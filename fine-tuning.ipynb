{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import cli\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_version = '2022-12-01'\n",
    "openai.api_base = os.getenv(\"EAST_US_OPENAI_API_BASE\")\n",
    "openai.api_type = 'azure'\n",
    "openai.api_key = os.getenv(\"EAST_US_OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the training file: training.jsonl\n",
      "Copying the training file to the validation file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'validation.jsonl'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습, 검증 데이터 파일 생성 \n",
    "import shutil\n",
    "import json\n",
    "\n",
    "training_file_name = 'training.jsonl'\n",
    "validation_file_name = 'validation.jsonl'\n",
    "\n",
    "sample_data = [{\"prompt\": \"When I go to the store, I want an\", \"completion\": \"apple.\"},\n",
    "    {\"prompt\": \"When I go to work, I want a\", \"completion\": \"coffee.\"},\n",
    "    {\"prompt\": \"When I go home, I want a\", \"completion\": \"soda.\"}]\n",
    "\n",
    "print(f'Generating the training file: {training_file_name}')\n",
    "with open(training_file_name, 'w') as training_file:\n",
    "    for entry in sample_data:\n",
    "        json.dump(entry, training_file)\n",
    "        training_file.write('\\n')\n",
    "\n",
    "print(f'Copying the training file to the validation file')\n",
    "shutil.copy(training_file_name, validation_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for existing uploaded files.\n",
      "Found 3 total uploaded files in the subscription.\n",
      "Found 2 already uploaded files that match our names.\n"
     ]
    }
   ],
   "source": [
    "# # OpenAI에 학습 및 검증 파일이 이미 업로드 되어있는지 확인 \n",
    "# print('Checking for existing uploaded files.')\n",
    "# results = []\n",
    "# files = openai.File.list().data\n",
    "# print(f'Found {len(files)} total uploaded files in the subscription.')\n",
    "# for item in files:\n",
    "#     if item[\"filename\"] in [training_file_name, validation_file_name]:\n",
    "#         results.append(item[\"id\"])\n",
    "# print(f'Found {len(results)} already uploaded files that match our names.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting already uploaded files...\n"
     ]
    }
   ],
   "source": [
    "# # 학습 및 검증 파일이 이미 OpenAI에 업로드되어 있다면 삭제\n",
    "# print(f'Deleting already uploaded files...')\n",
    "# for id in results:\n",
    "#     openai.File.delete(sid = id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upload progress: 100%|██████████| 204/204 [00:00<00:00, 205kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file from training.jsonl: file-9f319918c6854cf192e2fb9c2afa2f00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upload progress: 100%|██████████| 204/204 [00:00<00:00, 205kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file from validation.jsonl: file-c80354f9fdc14b60a8eef8638db793d5\n",
      "Status (training_file | validation_file): running | notRunning\n",
      "Status (training_file | validation_file): running | notRunning\n",
      "Status (training_file | validation_file): succeeded | running\n",
      "Status (training_file | validation_file): succeeded | running\n",
      "Status (training_file | validation_file): succeeded | running\n",
      "Status (training_file | validation_file): succeeded | succeeded\n"
     ]
    }
   ],
   "source": [
    "# OpenAI에 파일 업로드 및 업로드 상태 체크 \n",
    "import time\n",
    "\n",
    "def check_status(training_id, validation_id):\n",
    "    train_status = openai.File.retrieve(training_id)[\"status\"]\n",
    "    valid_status = openai.File.retrieve(validation_id)[\"status\"]\n",
    "    print(f'Status (training_file | validation_file): {train_status} | {valid_status}')\n",
    "    return (train_status, valid_status)\n",
    "\n",
    "#importing our two files\n",
    "training_id = cli.FineTune._get_or_upload(training_file_name, True)\n",
    "validation_id = cli.FineTune._get_or_upload(validation_file_name, True)\n",
    "\n",
    "#checking the status of the imports\n",
    "(train_status, valid_status) = check_status(training_id, validation_id)\n",
    "\n",
    "while train_status not in [\"succeeded\", \"failed\"] or valid_status not in [\"succeeded\", \"failed\"]:\n",
    "    time.sleep(1)\n",
    "    (train_status, valid_status) = check_status(training_id, validation_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading training file: file-9f319918c6854cf192e2fb9c2afa2f00\n",
      "{\"prompt\": \"When I go to the store, I want an\", \"completion\": \"apple.\"}\n",
      "{\"prompt\": \"When I go to work, I want a\", \"completion\": \"coffee.\"}\n",
      "{\"prompt\": \"When I go home, I want a\", \"completion\": \"soda.\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(f'Downloading training file: {training_id}')\n",
    "# result = openai.File.download(training_id)\n",
    "# print(result.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tunning model with jobID: ft-e0ef93edeec84e50b266d02b3a6106b4.\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "create_args = {\n",
    "    \"training_file\": training_id,\n",
    "    \"validation_file\": validation_id,\n",
    "    \"model\": \"babbage\",\n",
    "    \"compute_classification_metrics\": True,\n",
    "    \"classification_n_classes\": 3,\n",
    "    \"n_epochs\": 20,\n",
    "    \"batch_size\": 3,\n",
    "    \"learning_rate_multiplier\": 0.3\n",
    "}\n",
    "resp = openai.FineTune.create(**create_args)\n",
    "job_id = resp[\"id\"]\n",
    "status = resp[\"status\"]\n",
    "\n",
    "print(f'Fine-tunning model with jobID: {job_id}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming events for the fine-tuning job: ft-e0ef93edeec84e50b266d02b3a6106b4\n",
      "2023-04-21 13:47:24 Job enqueued. Waiting for jobs ahead to complete.\n",
      "2023-04-21 13:47:43 Job started.\n",
      "2023-04-21 13:48:39 Preprocessing started.\n",
      "Stream interrupted (client disconnected).\n"
     ]
    }
   ],
   "source": [
    "# import signal\n",
    "# import datetime\n",
    "\n",
    "# def signal_handler(sig, frame):\n",
    "#     status = openai.FineTune.retrieve(job_id).status\n",
    "#     print(f\"Stream interrupted. Job is still {status}.\")\n",
    "#     return\n",
    "\n",
    "# print(f'Streaming events for the fine-tuning job: {job_id}')\n",
    "# signal.signal(signal.SIGINT, signal_handler)\n",
    "\n",
    "# events = openai.FineTune.stream_events(job_id)\n",
    "# try:\n",
    "#     for event in events:\n",
    "#         print(f'{datetime.datetime.fromtimestamp(event[\"created_at\"])} {event[\"message\"]}')\n",
    "\n",
    "# except Exception:\n",
    "#     print(\"Stream interrupted (client disconnected).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job not in terminal status: running. Waiting.\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-ff2206b06a44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Job not in terminal status: {status}. Waiting.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"succeeded\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"failed\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFineTune\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"status\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Status: {status}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 상태 확인\n",
    "status = openai.FineTune.retrieve(id=job_id)[\"status\"]\n",
    "if status not in [\"succeeded\", \"failed\"]:\n",
    "    print(f'Job not in terminal status: {status}. Waiting.')\n",
    "    while status not in [\"succeeded\", \"failed\"]:\n",
    "        time.sleep(2)\n",
    "        status = openai.FineTune.retrieve(id=job_id)[\"status\"]\n",
    "        print(f'Status: {status}')\n",
    "else:\n",
    "    print(f'Finetune job {job_id} finished with status: {status}')\n",
    "\n",
    "print('Checking other finetune jobs in the subscription.')\n",
    "result = openai.FineTune.list()\n",
    "print(f'Found {len(result.data)} finetune jobs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new deployment with model: babbage.ft-fdb80b3a305843979b8508c55f387567\n"
     ]
    }
   ],
   "source": [
    "# 모델 배포 \n",
    "result = openai.FineTune.retrieve(id=job_id)\n",
    "if result[\"status\"] == 'succeeded':\n",
    "    model = result[\"fine_tuned_model\"]\n",
    "\n",
    "print(f'Creating a new deployment with model: {model}')\n",
    "result = openai.Deployment.create(model=model, scale_settings={\"scale_type\":\"standard\"})\n",
    "deployment_id = result[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for deployment status.\n",
      "Deployment deployment-e1eed3749c154a5c88158f62231b35be is with status: failed\n"
     ]
    }
   ],
   "source": [
    "# 배포 상태 확인 \n",
    "print(f'Checking for deployment status.')\n",
    "resp = openai.Deployment.retrieve(id=deployment_id)\n",
    "status = resp[\"status\"]\n",
    "print(f'Deployment {deployment_id} is with status: {status}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending a test completion job\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "The API deployment for the resource is not ready, please wait until provisioningState becomes Succeeded.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-a0d624cd3350>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Sending a test completion job'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstart_phrase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'When I go home, I want a'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCompletion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeployment_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeployment_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_phrase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'choices'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' .'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'\"{start_phrase} {text}.\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\eunjee\\anaconda3\\lib\\site-packages\\openai\\api_resources\\completion.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\eunjee\\anaconda3\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    151\u001b[0m         )\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[0;32m    154\u001b[0m             \u001b[1;34m\"post\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\eunjee\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         )\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\eunjee\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    618\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m             return (\n\u001b[1;32m--> 620\u001b[1;33m                 self._interpret_response_line(\n\u001b[0m\u001b[0;32m    621\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\eunjee\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    681\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"error\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 683\u001b[1;33m             raise self.handle_error_response(\n\u001b[0m\u001b[0;32m    684\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m             )\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: The API deployment for the resource is not ready, please wait until provisioningState becomes Succeeded."
     ]
    }
   ],
   "source": [
    "print('Sending a test completion job')\n",
    "start_phrase = 'When I go home, I want a'\n",
    "response = openai.Completion.create(deployment_id=deployment_id, prompt=start_phrase, temperature=0, stop=\".\")\n",
    "text = response['choices'][0]['text'].replace('\\n', '').replace(' .', '.').strip()\n",
    "print(f'\"{start_phrase} {text}.\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
